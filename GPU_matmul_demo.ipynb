{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Complementary material for the Frugal AI PSL week**\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Deyht/frugal_ai/blob/main/GPU_matmul_demo.ipynb)\n",
        "\n",
        "This notebook aims at demonstrating the performances of matrix multiplication operations on GPUs using the optimized cuBLAS (CUDA BLAS library). We also demonstrate how a naive matrix multiply kernel can be coded, and present a more complex custom implementation (inspired by cuTLASS design) to illustrate the type of low level optimization that are possible in GPGPU CUDA programming.\n",
        "\n",
        "This notebook is to be use as a complement to the practical work session on matmul optimization on CPU from the Frugal AI PSL week, therefore the provided codes follows a similar strucutre."
      ],
      "metadata": {
        "id": "gDPX3PZ_e2zB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **CuBLAS matmul**"
      ],
      "metadata": {
        "id": "_cK0Bi6xfsxL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile matmul_cublas.cu\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <cublas_v2.h>\n",
        "\n",
        "int main(int argc, char *argv[])\n",
        "{\n",
        "    size_t l_size = atoi(argv[1]);\n",
        "    size_t i;\n",
        "    int M, N, K;\n",
        "    float *A, *B, *C;\n",
        "    float alpha = 1.0f, beta = 0.0f;\n",
        "    M = l_size; N = l_size; K = l_size;\n",
        "\n",
        "    // Initializing cuBLAS by creating a handle and defining the precision (here pedantic = FP32)\n",
        "    // Only need to be done once, then all matmul operation can use the same handle\n",
        "    cublasHandle_t handle;\n",
        "    cublasStatus_t cublasStat = cublasCreate(&handle);\n",
        "    cublasSetMathMode(handle, CUBLAS_PEDANTIC_MATH);\n",
        "\n",
        "    // Allocate and fill the matrices on the host memory\n",
        "    A = (float*) calloc(M*K,sizeof(float));\n",
        "    B = (float*) calloc(K*N,sizeof(float));\n",
        "    C = (float*) calloc(M*N,sizeof(float));\n",
        "\n",
        "    for(i = 0; i < M*K; i++)\n",
        "      A[i] = ((float)rand()/RAND_MAX-0.5)*0.1;\n",
        "\n",
        "    for(i = 0; i < K*N; i++)\n",
        "      B[i] = ((float)rand()/RAND_MAX-0.5)*0.1;\n",
        "\n",
        "    // Allocate memory on the GPU to store the matrices\n",
        "    float *cu_A, *cu_B, *cu_C;\n",
        "\n",
        "    cudaMalloc(&cu_A, M*K*sizeof(float));\n",
        "    cudaMalloc(&cu_B, K*N*sizeof(float));\n",
        "    cudaMalloc(&cu_C, M*N*sizeof(float));\n",
        "\n",
        "    // Copy the matrices content from the host memory to the allocated sapce in GPU memory\n",
        "    cudaMemcpy(cu_A, A, M*K*sizeof(float), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(cu_B, B, K*N*sizeof(float), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(cu_C, C, M*N*sizeof(float), cudaMemcpyHostToDevice);\n",
        "\n",
        "    // CUDA kernels are asynchronous, so they cannot be timed with regulier host timers\n",
        "    // We rely on the dedicated \"cudaEvent\" to measure computation time\n",
        "    cudaEvent_t start, stop;\n",
        "    float elapsed_time = 0;\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&stop);\n",
        "\n",
        "    // Actual call to CuBLAS Sgemm function (timed with event records)\n",
        "    cudaEventRecord(start);\n",
        "    cublasSgemm(handle, CUBLAS_OP_N, CUBLAS_OP_N, M, N, K, &alpha, cu_A, M, cu_B, K, &beta, cu_C, M);\n",
        "    cudaEventRecord(stop);\n",
        "\n",
        "    //Get back the result matrix C content from the GPU to the host memory\n",
        "    cudaMemcpy(C, cu_C, M*N*sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Wait for asynchronous record over \"stop\" to terminate\n",
        "    cudaEventSynchronize(stop);\n",
        "    cudaEventElapsedTime(&elapsed_time, start, stop);\n",
        "\n",
        "    printf(\"%f\", elapsed_time/1000.0); //Convert back in seconds\n",
        "\n",
        "    exit(EXIT_SUCCESS);\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q8uOLmSEgdQt",
        "outputId": "e2bba80b-d1a6-4316-cdb1-466e16c42fe2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting matmul_cublas.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, sys\n",
        "\n",
        "# Invoke the cuda compiler with linking to the cuBLAS library\n",
        "# arch_sm is a flag specific to the used GPU architeture\n",
        "if os.system(\"nvcc -O3 -arch=sm_75 matmul_cublas.cu -o matmul_cublas -lm -lcublas -lcudart\"): sys.exit(\"Compilation error\")\n",
        "\n",
        "l_size = 4096\n",
        "\n",
        "elapsed_time_cublas_sgemm = float(os.popen(\"./matmul_cublas %d\"%(l_size)).read())\n",
        "gflops_cublas_sgemm = l_size**3/1e9/elapsed_time_cublas_sgemm\n",
        "print (\"cuBLAS SGEMM at size %d \\t time %f s \\t GFLOPS %f\"%(l_size, elapsed_time_cublas_sgemm, gflops_cublas_sgemm))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XenPiV01iwwz",
        "outputId": "ffa06fb1-a167-427f-f197-2edd84558b8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuBLAS SGEMM at size 16384 \t time 2.565427 s \t GFLOPS 1714.352625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Naiv CUDA kernel**\n",
        "\n",
        "Here we try to write the simplest possible kernel to parallelize matmul over the GPU using a classical 3-loop implementation. In CUDA programming, the kernel is execute by each CUDA thread, following the SIMT (Single Instruction Multiple Threads) formalism. The simplest way of coding a naive matmul is therefore to have each thread compute one element of the matrix $C$, by computing the loop over $K$. As we learned from the CPU practical work that memory continuity is key, we will adopt the formalism of matmul v3 and also include the transposition of matrix A prior to moving it to the GPU memory and calling the kernel.\n",
        "\n",
        "This is what is illustrated in the following cell."
      ],
      "metadata": {
        "id": "_L65rs_LrSS0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile matmul_cuda_naive.cu\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "\n",
        "\n",
        "__global__ void naive_cuda_matmul(float *A_T, float *B, float *C, int M, int N, int K, size_t l_size)\n",
        "{\n",
        "    int c_id = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    if(c_id >= l_size)\n",
        "      return;\n",
        "\n",
        "    int col = c_id / M;\n",
        "    int row = c_id % M;\n",
        "    float acc = 0.0;\n",
        "\n",
        "    for(int k=0; k < K; k++)\n",
        "      acc += A_T[row*K + k] * B[col*N + k];\n",
        "\n",
        "    C[c_id] = acc;\n",
        "}\n",
        "\n",
        "\n",
        "int main(int argc, char *argv[])\n",
        "{\n",
        "    size_t l_size = atoi(argv[1]);\n",
        "    size_t i, k;\n",
        "    int M, N, K;\n",
        "    float *A, *A_T, *B, *C;\n",
        "    M = l_size; N = l_size; K = l_size;\n",
        "\n",
        "    // Allocate and fill the matrices on the host memory\n",
        "    A = (float*) calloc(M*K,sizeof(float));\n",
        "    A_T = (float*) calloc(M*K,sizeof(float));\n",
        "    B = (float*) calloc(K*N,sizeof(float));\n",
        "    C = (float*) calloc(M*N,sizeof(float));\n",
        "\n",
        "    for(i = 0; i < M*K; i++)\n",
        "      A[i] = sqrt(i)*0.0001;//((float)rand()/RAND_MAX-0.5)*0.1;\n",
        "\n",
        "    for(i = 0; i < K*N; i++)\n",
        "      B[i] = sqrt(i)*0.0001; //((float)rand()/RAND_MAX-0.5)*0.1;\n",
        "\n",
        "    //Transpose in advance in the CPU\n",
        "    for(i = 0; i < M; i++)\n",
        "        for(k = 0; k < K; k++)\n",
        "            A_T[i*K+k] = A[k*M+i];\n",
        "\n",
        "    // Allocate memory on the GPU to store the matrices\n",
        "    float *cu_A_T, *cu_B, *cu_C;\n",
        "\n",
        "    cudaMalloc(&cu_A_T, M*K*sizeof(float));\n",
        "    cudaMalloc(&cu_B, K*N*sizeof(float));\n",
        "    cudaMalloc(&cu_C, M*N*sizeof(float));\n",
        "\n",
        "    // Copy the matrices content from the host memory to the allocated sapce in GPU memory\n",
        "    cudaMemcpy(cu_A_T, A_T, M*K*sizeof(float), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(cu_B, B, K*N*sizeof(float), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(cu_C, C, M*N*sizeof(float), cudaMemcpyHostToDevice);\n",
        "\n",
        "    // CUDA kernels are asynchronous, so they cannot be timed with regulier host timers\n",
        "    // We rely on the dedicated \"cudaEvent\" to measure computation time\n",
        "    cudaEvent_t start, stop;\n",
        "    float elapsed_time = 0;\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&stop);\n",
        "\n",
        "    // CUDA kernels are launched as logical thread blocks\n",
        "    // Here we define how we want to distribute the work over the C matrix\n",
        "\n",
        "    int cu_threads = 256;\n",
        "  \tint cu_blocks = (M * N + cu_threads - 1) / cu_threads;\n",
        "\n",
        "    // Actual call to the matmul function/kernel (timed with event records)\n",
        "    cudaEventRecord(start);\n",
        "    naive_cuda_matmul<<< cu_blocks, cu_threads >>>(cu_A_T, cu_B, cu_C, M, N, K, M*N);\n",
        "    cudaEventRecord(stop);\n",
        "\n",
        "    //Get back the result matrix C content from the GPU to the host memory\n",
        "    cudaMemcpy(C, cu_C, M*N*sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Wait for asynchronous record over \"stop\" to terminate\n",
        "    cudaEventSynchronize(stop);\n",
        "    cudaEventElapsedTime(&elapsed_time, start, stop);\n",
        "\n",
        "    printf(\"%f\", elapsed_time/1000.0); //Convert back in seconds\n",
        "\n",
        "    exit(EXIT_SUCCESS);\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJ-XobgirX2R",
        "outputId": "338fac59-29e7-42d1-acf2-a25fd14c1bfe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting matmul_cuda_naive.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, sys\n",
        "\n",
        "# Invoke the cuda compiler with linking to the cuBLAS library\n",
        "# arch_sm is a flag specific to the used GPU architeture\n",
        "if os.system(\"nvcc -O3 -arch=sm_75 matmul_cuda_naive.cu -o matmul_cuda_naive -lm\"): sys.exit(\"Compilation error\")\n",
        "\n",
        "l_size = 4096\n",
        "\n",
        "elapsed_time_cuda_naive = float(os.popen(\"./matmul_cuda_naive %d\"%(l_size)).read())\n",
        "gflops_cuda_naive = l_size**3/1e9/elapsed_time_cuda_naive\n",
        "print (\"Matmul CUDA naive at size %d \\t time %f s \\t GFLOPS %f\"%(l_size, elapsed_time_cuda_naive, gflops_cuda_naive))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wTK4UE4y1CJu",
        "outputId": "5603c00e-27a9-4f34-d393-95f903b2f08a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matmul CUDA naive at size 8192 \t time 34.941535 s \t GFLOPS 15.733591\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Custom implementation**\n",
        "\n",
        "Following [cuTLASS matmul strategy](https://developer.nvidia.com/blog/cutlass-linear-algebra-cuda/), the following cell propose a custom implementation that includes global matrix blocking, thread block tiling, and warp tiling. This optimize memory reuse at the level of per-thread-block shared memory and register memory at the warp level.\n",
        "\n",
        "This custom version reaches near 60% of the compute performances of the classical cuBLAS sgemm imlplementation on a T4 GPU depending the matrix size. The tiling size being fixed the performances can vary strongly from on GPU to the other."
      ],
      "metadata": {
        "id": "n7BI0Cew1kjk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile matmul_cuda_custom_sgemm.cu\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "\n",
        "\n",
        "#define BlockDimM 64\n",
        "#define BlockDimN 64\n",
        "#define BlockDimK 4\n",
        "\n",
        "#define WarpDimM 32\n",
        "#define WarpDimN 16\n",
        "#define WarpDimK 1\n",
        "\n",
        "#define ThreadDimM 4\n",
        "#define ThreadDimN 4\n",
        "\n",
        "\n",
        "__global__ void custom_sgemm(int TransA, int TransB,\n",
        "    int M, int N, int K,\n",
        "    float alpha,\n",
        "    float *A, int lda,\n",
        "    float *B, int ldb,\n",
        "    float beta,\n",
        "    float *C, int ldc)\n",
        "{\n",
        "\n",
        "    int block_row = blockIdx.x;\n",
        "    int block_col = blockIdx.y;\n",
        "\n",
        "    float frag_a[ThreadDimM];\n",
        "    float frag_b[ThreadDimN];\n",
        "\n",
        "    float accumulator[ThreadDimN][ThreadDimM];\n",
        "\n",
        "    int c_id = threadIdx.y*blockDim.x + threadIdx.x;\n",
        "    int warp_id = c_id / 32;\n",
        "    int thread_id = c_id % 32;\n",
        "\n",
        "    int warp_x = warp_id / (BlockDimM/WarpDimM);\n",
        "    int warp_y = warp_id % (BlockDimM/WarpDimM);\n",
        "\n",
        "    int frag_x = thread_id / (WarpDimM/ThreadDimM);\n",
        "    int frag_y = thread_id % (WarpDimM/ThreadDimM);\n",
        "\n",
        "    float *data_block_A;\n",
        "    float *data_block_B;\n",
        "    float *data_block_C;\n",
        "\n",
        "    __shared__ float As[BlockDimK][BlockDimM];\n",
        "    __shared__ float Bs[BlockDimN][BlockDimK];\n",
        "\n",
        "    int l, e_per_th, p_x, p_y;\n",
        "\n",
        "    data_block_C = &C[block_col*BlockDimN*M + block_row*BlockDimM];\n",
        "\n",
        "    #pragma unroll\n",
        "    for(int thread_x = 0; thread_x < ThreadDimN; thread_x ++)\n",
        "      #pragma unroll\n",
        "      for(int thread_y = 0; thread_y < ThreadDimM; thread_y++)\n",
        "        accumulator[thread_x][thread_y] = 0.0f;\n",
        "\n",
        "    for(int block_k = 0; block_k < (K/BlockDimK); block_k++)\n",
        "    {\n",
        "      data_block_A = &A[block_k*BlockDimK*M + block_row*BlockDimM];\n",
        "      data_block_B = &B[block_col*BlockDimN*K + block_k*BlockDimK];\n",
        "\n",
        "      e_per_th = (BlockDimM*BlockDimK)/(blockDim.x*blockDim.y);\n",
        "      for(l = 0; l < e_per_th; l++)\n",
        "      {\n",
        "        p_x = (c_id*e_per_th + l)/BlockDimM;\n",
        "        p_y = (c_id*e_per_th + l)%BlockDimM;\n",
        "\n",
        "        As[p_x][p_y] = data_block_A[p_x*M + p_y];\n",
        "      }\n",
        "\n",
        "      __syncthreads();\n",
        "\n",
        "      e_per_th = (BlockDimN*BlockDimK)/(blockDim.x*blockDim.y);\n",
        "      for(l = 0; l < e_per_th; l++)\n",
        "      {\n",
        "        p_x = (c_id*e_per_th + l)/BlockDimK;\n",
        "        p_y = (c_id*e_per_th + l)%BlockDimK;\n",
        "\n",
        "        Bs[p_x][p_y] = data_block_B[p_x*K + p_y];\n",
        "      }\n",
        "\n",
        "      __syncthreads();\n",
        "\n",
        "      #pragma unroll\n",
        "      for(int warp_k = 0; warp_k < BlockDimK; warp_k++)\n",
        "      {\n",
        "        #pragma unroll\n",
        "        for(int thread_y = 0; thread_y < ThreadDimM; thread_y++)\n",
        "          frag_a[thread_y] = As[warp_k][warp_y*WarpDimM + frag_y*ThreadDimM + thread_y];\n",
        "        #pragma unroll\n",
        "        for(int thread_x = 0; thread_x < ThreadDimN; thread_x ++)\n",
        "          frag_b[thread_x] = Bs[warp_x*WarpDimN + frag_x*ThreadDimN + thread_x][warp_k];\n",
        "\n",
        "        #pragma unroll\n",
        "        for(int thread_x = 0; thread_x < ThreadDimN; thread_x ++)\n",
        "          #pragma unroll\n",
        "          for(int thread_y = 0; thread_y < ThreadDimM; thread_y++)\n",
        "            accumulator[thread_x][thread_y] +=\n",
        "              frag_a[thread_y]*frag_b[thread_x];\n",
        "      }\n",
        "      __syncthreads();\n",
        "    }\n",
        "\n",
        "    #pragma unroll\n",
        "    for(int thread_x = 0; thread_x < ThreadDimN; thread_x ++)\n",
        "    {\n",
        "\n",
        "      #pragma unroll\n",
        "      for(int thread_y = 0; thread_y < ThreadDimM; thread_y++)\n",
        "\n",
        "        data_block_C[(warp_x*WarpDimN + frag_x*ThreadDimN + thread_x)*M + (warp_y*WarpDimM + frag_y*ThreadDimM + thread_y)] =\n",
        "          alpha*accumulator[thread_x][thread_y] + beta*data_block_C[(warp_x*WarpDimN + frag_x*ThreadDimN + thread_x)*M + (warp_y*WarpDimM + frag_y*ThreadDimM + thread_y)] ;\n",
        "    }\n",
        "\n",
        "}\n",
        "\n",
        "\n",
        "int main(int argc, char *argv[])\n",
        "{\n",
        "    size_t l_size = atoi(argv[1]);\n",
        "    size_t i;\n",
        "    int M, N, K;\n",
        "    float *A, *B, *C;\n",
        "    M = l_size; N = l_size; K = l_size;\n",
        "\n",
        "    // Allocate and fill the matrices on the host memory\n",
        "    A = (float*) calloc(M*K,sizeof(float));\n",
        "    B = (float*) calloc(K*N,sizeof(float));\n",
        "    C = (float*) calloc(M*N,sizeof(float));\n",
        "\n",
        "    for(i = 0; i < M*K; i++)\n",
        "      A[i] = sqrt(i)*0.0001;//((float)rand()/RAND_MAX-0.5)*0.1;\n",
        "\n",
        "    for(i = 0; i < K*N; i++)\n",
        "      B[i] = sqrt(i)*0.0001; //((float)rand()/RAND_MAX-0.5)*0.1;\n",
        "\n",
        "    // Allocate memory on the GPU to store the matrices\n",
        "    float *cu_A, *cu_B, *cu_C;\n",
        "\n",
        "    cudaMalloc(&cu_A, M*K*sizeof(float));\n",
        "    cudaMalloc(&cu_B, K*N*sizeof(float));\n",
        "    cudaMalloc(&cu_C, M*N*sizeof(float));\n",
        "\n",
        "    // Copy the matrices content from the host memory to the allocated sapce in GPU memory\n",
        "    cudaMemcpy(cu_A, A, M*K*sizeof(float), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(cu_B, B, K*N*sizeof(float), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(cu_C, C, M*N*sizeof(float), cudaMemcpyHostToDevice);\n",
        "\n",
        "    // CUDA kernels are asynchronous, so they cannot be timed with regulier host timers\n",
        "    // We rely on the dedicated \"cudaEvent\" to measure computation time\n",
        "    cudaEvent_t start, stop;\n",
        "    float elapsed_time = 0;\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&stop);\n",
        "\n",
        "    // CUDA kernels are launched as logical thread blocks\n",
        "    // Here we define how we want to distribute the work over the C matrix\n",
        "\n",
        "    dim3 threadsPerBlock(BlockDimM/ThreadDimM, BlockDimN/ThreadDimN);\n",
        "    dim3 numBlocks(M/BlockDimM, N/BlockDimN);\n",
        "\n",
        "    // Actual call to the matmul function/kernel (timed with event records)\n",
        "    cudaEventRecord(start);\n",
        "    custom_sgemm<<< numBlocks, threadsPerBlock >>>(0, 0, M, N, K, 1.0, cu_A, M, cu_B, K, 0.0, cu_C, M);\n",
        "    cudaEventRecord(stop);\n",
        "\n",
        "    //Get back the result matrix C content from the GPU to the host memory\n",
        "    cudaMemcpy(C, cu_C, M*N*sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Wait for asynchronous record over \"stop\" to terminate\n",
        "    cudaEventSynchronize(stop);\n",
        "    cudaEventElapsedTime(&elapsed_time, start, stop);\n",
        "\n",
        "    printf(\"%f\", elapsed_time/1000.0); //Convert back in seconds\n",
        "\n",
        "    exit(EXIT_SUCCESS);\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4WbCfuOR25FP",
        "outputId": "ed0d14c8-eca0-45f2-8b83-cfa42db536b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting matmul_cuda_custom_sgemm.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Invoke the cuda compiler with linking to the cuBLAS library\n",
        "# arch_sm is a flag specific to the used GPU architeture\n",
        "if os.system(\"nvcc -O3 -arch=sm_75 matmul_cuda_custom_sgemm.cu -o matmul_cuda_custom_sgemm -lm\"): sys.exit(\"Compilation error\")\n",
        "\n",
        "l_size = 4096\n",
        "\n",
        "elapsed_time_custom_sgemm = float(os.popen(\"./matmul_cuda_custom_sgemm %d\"%(l_size)).read())\n",
        "gflops_custom_sgemm = l_size**3/1e9/elapsed_time_custom_sgemm\n",
        "print (\"Matmul CUDA naive at size %d \\t time %f s \\t GFLOPS %f\"%(l_size, elapsed_time_custom_sgemm, gflops_custom_sgemm))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_InfOfWt3qqv",
        "outputId": "9b857824-b729-4970-a574-5930720f1f12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matmul CUDA naive at size 16384 \t time 5.202236 s \t GFLOPS 845.414647\n"
          ]
        }
      ]
    }
  ]
}
